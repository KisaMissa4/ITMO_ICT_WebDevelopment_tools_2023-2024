# Использование Celery для Асинхронной Очереди Задач

## 1. Что такое Celery?

Celery — это распределённая система очередей задач с открытым исходным кодом, которая позволяет запускать и управлять задачами
в фоновом режиме. Основная задача Celery — это асинхронное выполнение задач (tasks) с возможностью масштабирования и
балансировки нагрузки. Celery обычно используется для фоновой обработки длительных задач, таких как отправка электронной почты,
выполнение сложных вычислений, интеграция с внешними API или сбор данных с сайтов.

### Основные возможности Celery:

- **Асинхронная обработка**: Выполняет задачи в фоне, не блокируя основной поток работы приложения.
- **Очереди задач**: Позволяет ставить задачи в очередь и обрабатывать их по мере освобождения ресурсов.
- **Масштабируемость**: Легко масштабируется горизонтально, добавляя воркеры для обработки задач.
- **Поддержка различных брокеров**: В качестве брокера сообщений можно использовать Redis, RabbitMQ и другие.

## 2. Зачем нужен Celery в этом проекте?

В данном проекте Celery используется для асинхронного парсинга новых проектов с сайта. Парсинг страниц и добавление данных в
базу данных может быть длительным процессом, особенно если страниц много. Вместо того чтобы выполнять эту задачу в основном
потоке, Celery ставит её в очередь и обрабатывает в фоне. Это позволяет основному приложению оставаться отзывчивым и не
зависеть от выполнения длительных операций.

### Пример использования:

```python
app = celery.Celery('queue', broker=config.redis.dsn, backend=config.redis.dsn)
```

Здесь создаётся объект приложения Celery. Для обмена сообщениями между приложением и Celery используется **Redis** как брокер
сообщений и хранилище результатов выполнения задач (backend).

### Определение задачи Celery:

```python
@app.task
def upload_new_projects(page: int) -> int:
    return asyncio.run(parse.upload_new_projects(page))
```

Задача `upload_new_projects` отвечает за загрузку новых проектов с указанной страницы. Задача парсит данные с сайта и добавляет
их в базу данных. Благодаря Celery эта задача может выполняться в фоновом режиме, не блокируя основной поток приложения.

## 3. Как Celery интегрируется в FastAPI?

Celery можно интегрировать в приложение на FastAPI для асинхронной обработки задач. В данном проекте это реализовано с помощью
двух маршрутов:

- **Загрузка новых проектов**:

```python
@router.post("/upload", response_model=schemas.Queue)
async def upload_projects(
    schema: schemas.ProjectUpload,
    user: tp.Annotated[models.User, Depends(dependencies.get_user)],
):
    task = queue.upload_new_projects.delay(schema.page)
    return schemas.Queue(id=task.id, status=task.status, result=task.result)
```

Этот маршрут принимает запрос на загрузку проектов с определённой страницы. Вместо того чтобы сразу загружать проекты,
создаётся задача Celery с помощью метода `.delay()`. Задача отправляется в очередь, и пользователю сразу возвращается
идентификатор задачи и её текущий статус.

- **Получение статуса задачи**:

```python
@router.get("/upload/{queue_id}", response_model=schemas.Queue)
async def get_upload_status(
    queue_id: str,
):
    task = queue.upload_new_projects.AsyncResult(queue_id)
    return schemas.Queue(id=task.id, status=task.status, result=task.result)
```

Этот маршрут позволяет получить статус выполнения задачи по её идентификатору. С помощью метода `AsyncResult` можно узнать
текущее состояние задачи (выполняется, завершена или произошла ошибка), а также результат выполнения (если задача уже
завершена).

## 4. Процесс парсинга и сохранения данных

Асинхронная функция `upload_new_projects(page)` занимается:

- Получением контента с веб-страницы через асинхронный HTTP-запрос.
- Парсингом данных с помощью `BeautifulSoup`.
- Добавлением новых проектов в базу данных через асинхронную сессию SQLAlchemy.

### Пример кода:

```python
async def upload_new_projects(page: int) -> int:
    async with AsyncSession(engine) as session:
        content = await async_get_content(page)
        data_list = parse_data(content)
        for title, description, is_active, start_date in data_list:
            project = models.Project(title=title, description=description, is_active=is_active, start_date=start_date)
            session.add(project)
        await session.commit()

    return len(data_list)
```

Здесь:

- **`async_get_content(page)`** — асинхронно получает контент страницы.
- **`parse_data(content)`** — парсит контент и извлекает нужные данные (название, описание, теги).
- **`session.add(project)`** — добавляет проект в базу данных.
- **`session.commit()`** — фиксирует изменения в базе данных.

## 5. Как работает Celery?

Когда пользователь отправляет запрос на загрузку новых проектов, Celery выполняет следующие шаги:

1. Запускает задачу `upload_new_projects`.
2. Задача ставится в очередь, а воркер Celery забирает её на выполнение.
3. После выполнения задачи результат сохраняется в Redis (или другом бэкенде).
4. Пользователь может в любой момент запросить статус задачи по её ID и узнать, завершена ли она.

### Преимущества использования Celery:

- **Асинхронное выполнение задач**: Основной поток приложения не блокируется длительными операциями.
- **Масштабируемость**: Можно запустить несколько воркеров Celery для параллельной обработки большого числа задач.
- **Отслеживание статуса задач**: Celery предоставляет удобные инструменты для отслеживания выполнения задач и получения их
  результатов.

Celery идеально подходит для работы с фоновыми задачами, особенно если требуется высокая производительность и обработка
большого объёма данных.

```